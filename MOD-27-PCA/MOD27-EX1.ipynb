{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Definir os caminhos dos arquivos de dados\n",
    "caminho_features = \"./data/UCI HAR Dataset/features.txt\"\n",
    "caminho_labels = \"./data/UCI HAR Dataset/activity_labels.txt\"\n",
    "caminho_subtrain = \"./data/UCI HAR Dataset/train/subject_train.txt\"\n",
    "caminho_xtrain = \"./data/UCI HAR Dataset/train/X_train.txt\"\n",
    "caminho_ytrain = \"./data/UCI HAR Dataset/train/y_train.txt\"\n",
    "caminho_subtest = \"./data/UCI HAR Dataset/test/subject_test.txt\"\n",
    "caminho_xtest = \"./data/UCI HAR Dataset/test/X_test.txt\"\n",
    "caminho_ytest = \"./data/UCI HAR Dataset/test/y_test.txt\"\n",
    "\n",
    "# Ler as características e rótulos\n",
    "caracteristicas = pd.read_csv(caminho_features, header=None, names=['nome_var'], sep=r'\\s+')\n",
    "rotulos = pd.read_csv(caminho_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "# Ler os dados de treinamento\n",
    "sujeito_treino = pd.read_csv(caminho_subtrain, header=None, names=['subject_id'])\n",
    "colunas_x_treino = [f\"feature_{i}\" for i in range(1, len(caracteristicas) + 1)]\n",
    "X_treino = pd.read_csv(caminho_xtrain, delim_whitespace=True, header=None, names=colunas_x_treino)\n",
    "y_treino = pd.read_csv(caminho_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "# Ler os dados de teste\n",
    "sujeito_teste = pd.read_csv(caminho_subtest, header=None, names=['subject_id'])\n",
    "colunas_x_teste = [f\"feature_{i}\" for i in range(1, len(caracteristicas) + 1)]\n",
    "X_teste = pd.read_csv(caminho_xtest, delim_whitespace=True, header=None, names=colunas_x_teste)\n",
    "y_teste = pd.read_csv(caminho_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de decisão\n",
    "\n",
    "Rode uma árvore de decisão com todas as variáveis, utilizando o ```ccp_alpha=0.001```. Avalie a acurácia nas bases de treinamento e teste. Avalie o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------+\n",
      "|         Métrica         | Valor  |\n",
      "+-------------------------+--------+\n",
      "| Acurácia no treinamento | 0.9758 |\n",
      "|    Acurácia no teste    | 0.8799 |\n",
      "+-------------------------+--------+\n",
      "CPU times: total: 3.42 s\n",
      "Wall time: 4.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Criar e treinar a árvore de decisão com ccp_alpha=0.001\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.001, random_state=42)\n",
    "clf.fit(X_treino, y_treino.values.ravel())\n",
    "\n",
    "# Avaliar a acurácia nos conjuntos de treinamento e teste\n",
    "acc_treino = accuracy_score(y_treino, clf.predict(X_treino))\n",
    "acc_teste = accuracy_score(y_teste, clf.predict(X_teste))\n",
    "\n",
    "# Criar uma tabela com os resultados\n",
    "tabela = PrettyTable([\"Métrica\", \"Valor\"])\n",
    "tabela.add_row([\"Acurácia no treinamento\", f\"{acc_treino:.4f}\"])\n",
    "tabela.add_row([\"Acurácia no teste\", f\"{acc_teste:.4f}\"])\n",
    "print(tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça uma análise de componemtes principais das variáveis originais. Utilize apenas uma componente. Faça uma árvore de decisão com esta componente como variável explicativa.\n",
    "\n",
    "- Avalie a acurácia nas bases de treinamento e teste\n",
    "- Avalie o tempo de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------+\n",
      "|            Métrica            | Valor  |\n",
      "+-------------------------------+--------+\n",
      "| Acurácia no treinamento (PCA) | 0.4997 |\n",
      "|    Acurácia no teste (PCA)    | 0.4571 |\n",
      "+-------------------------------+--------+\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Realizar a Análise de Componentes Principais (PCA)\n",
    "pca = PCA(n_components=1)\n",
    "X_train_pca = pca.fit_transform(X_treino)\n",
    "X_test_pca = pca.transform(X_teste)\n",
    "\n",
    "# Criar e treinar a árvore de decisão com a única componente principal\n",
    "clf_pca = DecisionTreeClassifier(ccp_alpha=0.001, random_state=42)\n",
    "clf_pca.fit(X_train_pca, y_treino.values.ravel())\n",
    "\n",
    "# Avaliar a acurácia nos conjuntos de treinamento e teste (PCA)\n",
    "acc_treino_pca = accuracy_score(y_treino, clf_pca.predict(X_train_pca))\n",
    "acc_teste_pca = accuracy_score(y_teste, clf_pca.predict(X_test_pca))\n",
    "\n",
    "# Criar uma tabela com os resultados (PCA)\n",
    "tabela_pca = PrettyTable([\"Métrica\", \"Valor\"])\n",
    "tabela_pca.add_row([\"Acurácia no treinamento (PCA)\", f\"{acc_treino_pca:.4f}\"])\n",
    "tabela_pca.add_row([\"Acurácia no teste (PCA)\", f\"{acc_teste_pca:.4f}\"])\n",
    "print(tabela_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o número de componentes\n",
    "\n",
    "Com base no código acima, teste a árvore de classificação com pelo menos as seguintes possibilidades de quantidades de componentes: ```[1, 2, 5, 10, 50]```. Avalie para cada uma delas:\n",
    "\n",
    "- Acurácia nas bases de treino e teste\n",
    "- Tempo de processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Utilizando 1 componente(s) principal(is):\n",
      "\n",
      "Utilizando 2 componente(s) principal(is):\n",
      "\n",
      "Utilizando 5 componente(s) principal(is):\n",
      "\n",
      "Utilizando 10 componente(s) principal(is):\n",
      "\n",
      "Utilizando 50 componente(s) principal(is):\n",
      "+---------------+-------------------------+-------------------+\n",
      "| # Componentes | Acurácia no Treinamento | Acurácia no Teste |\n",
      "+---------------+-------------------------+-------------------+\n",
      "|       1       |          0.4954         |       0.4693      |\n",
      "|       2       |          0.6128         |       0.5847      |\n",
      "|       5       |          0.8460         |       0.7886      |\n",
      "|       10      |          0.8927         |       0.8246      |\n",
      "|       50      |          0.9029         |       0.8174      |\n",
      "+---------------+-------------------------+-------------------+\n",
      "CPU times: total: 3.31 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Definir a lista de componentes a serem testados\n",
    "componentes = [1, 2, 5, 10, 50]\n",
    "\n",
    "# Criar tabela geral para armazenar os resultados\n",
    "tabela_geral = PrettyTable([\"# Componentes\", \"Acurácia no Treinamento\", \"Acurácia no Teste\"])\n",
    "\n",
    "# Para cada número de componentes\n",
    "for n_comp in componentes:\n",
    "    print(f\"\\nUtilizando {n_comp} componente(s) principal(is):\")\n",
    "    \n",
    "    # Realizar a Análise de Componentes Principais (PCA)\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    X_train_pca = pca.fit_transform(X_treino)\n",
    "    X_test_pca = pca.transform(X_teste)\n",
    "    \n",
    "    # Criar um dicionário de parâmetros para GridSearchCV\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    # Criar o GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=DecisionTreeClassifier(ccp_alpha=0.001, random_state=42),\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=5,\n",
    "                               n_jobs=-1)\n",
    "    \n",
    "    # Ajustar o GridSearchCV\n",
    "    grid_search.fit(X_train_pca, y_treino.values.ravel())\n",
    "    \n",
    "    # Avaliar a acurácia nos conjuntos de treinamento e teste com os melhores parâmetros\n",
    "    clf_pca = grid_search.best_estimator_\n",
    "    acc_treino_pca = accuracy_score(y_treino, clf_pca.predict(X_train_pca))\n",
    "    acc_teste_pca = accuracy_score(y_teste, clf_pca.predict(X_test_pca))\n",
    "    \n",
    "    # Adicionar resultados à tabela geral\n",
    "    tabela_geral.add_row([n_comp, f\"{acc_treino_pca:.4f}\", f\"{acc_teste_pca:.4f}\"])\n",
    "\n",
    "print(tabela_geral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclua\n",
    "\n",
    "- O que aconteceu com a acurácia?\n",
    "- O que aconteceu com o tempo de processamento?\n",
    "\n",
    "---------------------------------------------------------------\n",
    "\n",
    "A árvore de decisão, sem a aplicação do PCA, apresentou uma acurácia superior, porém exigiu um tempo de processamento maior;\n",
    "\n",
    "O aumento no número de componentes principais melhorou consideravelmente a acurácia do modelo de Árvore de Decisão, tanto no conjunto de treinamento quanto no conjunto de teste;\n",
    "\n",
    "À medida que mais componentes são adicionados, o tempo de processamento tende a aumentar, pois o modelo precisa lidar com um maior número de variáveis;\n",
    "\n",
    "Existe um trade-off entre acurácia e velocidade de processamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
