{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cite 5 diferenças entre o Random Forest e o AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Método de Construção: O Random Forest usa árvores de decisão independentes, enquanto o AdaBoost usa modelos fracos sequenciais.\n",
    "\n",
    "- Peso das Instâncias: No AdaBoost, as instâncias mal classificadas têm mais peso, enquanto no Random Forest todas têm o mesmo peso.\n",
    "\n",
    "- Forma de Combinação: O Random Forest usa votação majoritária, enquanto o AdaBoost usa pesos de precisão.\n",
    "\n",
    "- Sensibilidade a Outliers: O AdaBoost é mais sensível, enquanto o Random Forest é mais robusto.\n",
    "\n",
    "- Complexidade do Modelo Final: O Random Forest produz modelos mais complexos, enquanto o AdaBoost produz modelos mais simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Acesse o link Scikit-learn–adaboost, leia a explicação e crie um jupyter notebook contendo o exemplo do AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.94 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.91 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "    voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cite 5 Hyperparametros importantes no AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators: Quantidade de modelos fracos.\n",
    "\n",
    "- learning_rate: Peso de cada modelo.\n",
    "\n",
    "- base_estimator: Tipo de modelo fraco.\n",
    "\n",
    "- algorithm: Método de cálculo dos pesos.\n",
    "\n",
    "- random_state: Semente aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hyperparâmetros encontrados:\n",
      "+------------------+--------------+\n",
      "|  Hyperparâmetro  | Melhor Valor |\n",
      "+------------------+--------------+\n",
      "|      lr__C       |     1.0      |\n",
      "| rf__n_estimators |      10      |\n",
      "|      voting      |     hard     |\n",
      "+------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Definindo os hyperparâmetros a serem testados\n",
    "params = {\n",
    "    'lr__C': [0.1, 1.0, 10.0],\n",
    "    'rf__n_estimators': [10, 50, 100],\n",
    "    'voting': ['hard']\n",
    "}\n",
    "\n",
    "# Criando o objeto GridSearchCV\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "\n",
    "# Realizando a busca dos melhores hyperparâmetros\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Obtendo os resultados\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# Criando a tabela\n",
    "table = PrettyTable([\"Hyperparâmetro\", \"Melhor Valor\"])\n",
    "for param_name, param_value in best_params.items():\n",
    "    table.add_row([param_name, param_value])\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(\"Melhores hyperparâmetros encontrados:\")\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
