{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cite 5 diferenças entre o Random Forest e o AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Método de Construção: O Random Forest usa árvores de decisão independentes, enquanto o AdaBoost usa modelos fracos sequenciais.\n",
    "\n",
    "- Peso das Instâncias: No AdaBoost, as instâncias mal classificadas têm mais peso, enquanto no Random Forest todas têm o mesmo peso.\n",
    "\n",
    "- Forma de Combinação: O Random Forest usa votação majoritária, enquanto o AdaBoost usa pesos de precisão.\n",
    "\n",
    "- Sensibilidade a Outliers: O AdaBoost é mais sensível, enquanto o Random Forest é mais robusto.\n",
    "\n",
    "- Complexidade do Modelo Final: O Random Forest produz modelos mais complexos, enquanto o AdaBoost produz modelos mais simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Acesse o link Scikit-learn–adaboost, leia a explicação e crie um jupyter notebook contendo o exemplo do AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.94 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.91 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "    voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cite 5 Hyperparametros importantes no AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators: Quantidade de modelos fracos.\n",
    "\n",
    "- learning_rate: Peso de cada modelo.\n",
    "\n",
    "- base_estimator: Tipo de modelo fraco.\n",
    "\n",
    "- algorithm: Método de cálculo dos pesos.\n",
    "\n",
    "- random_state: Semente aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hyperparâmetros encontrados:\n",
      "+------------------+--------------+\n",
      "|  Hyperparâmetro  | Melhor Valor |\n",
      "+------------------+--------------+\n",
      "|      lr__C       |     1.0      |\n",
      "| rf__n_estimators |      10      |\n",
      "|      voting      |     hard     |\n",
      "+------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Definindo os hyperparâmetros a serem testados\n",
    "params = {\n",
    "    'lr__C': [0.1, 1.0, 10.0],\n",
    "    'rf__n_estimators': [10, 50, 100],\n",
    "    'voting': ['hard']\n",
    "}\n",
    "\n",
    "# Criando o objeto GridSearchCV\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "\n",
    "# Realizando a busca dos melhores hyperparâmetros\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Obtendo os resultados\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# Criando a tabela\n",
    "table = PrettyTable([\"Hyperparâmetro\", \"Melhor Valor\"])\n",
    "for param_name, param_value in best_params.items():\n",
    "    table.add_row([param_name, param_value])\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(\"Melhores hyperparâmetros encontrados:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cite 5 diferenças entre o AdaBoost e o GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ênfase em Exemplos Difíceis:\n",
    "- AdaBoost: Atribui pesos às amostras mal classificadas para dar mais atenção a elas.\n",
    "- GBM: Ajusta os pesos usando o gradiente do erro para minimizar a perda global.\n",
    "\n",
    "Taxa de Aprendizado:\n",
    "- AdaBoost: Usa uma taxa de aprendizado fixa.\n",
    "- GBM: Permite variar a taxa de aprendizado.\n",
    "\n",
    "Robustez a Outliers:\n",
    "- AdaBoost: Mais sensível a outliers e ruídos.\n",
    "- GBM: Mais robusto a esses problemas.\n",
    "\n",
    "Complexidade dos Preditores:\n",
    "- AddaBoost: Requer preditores fracos.\n",
    "- GBM: Pode usar preditores fortes, como árvores profundas.\n",
    "\n",
    "Funções de Perda:\n",
    "- AdaBoost: Tem duas opções de função de perda.\n",
    "- GBM: Pode usar qualquer função de perda diferenciável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Acesse o link Scikit-learn – GBM, leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo de classificação e de regressão do GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de Classificação GBM:\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X, y = make_hastie_10_2(random_state=0)\n",
    "X_train, X_test = X[:2000], X[2000:]\n",
    "y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.009154859960321"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo de Regressão GBM:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X, y = make_friedman1(n_samples=1200, random_state=0, noise=1.0)\n",
    "X_train, X_test = X[:200], X[200:]\n",
    "y_train, y_test = y[:200], y[200:]\n",
    "est = GradientBoostingRegressor(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0,\n",
    "    loss='squared_error'\n",
    ").fit(X_train, y_train)\n",
    "mean_squared_error(y_test, est.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cite 5 Hyperparametros importantes no GBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators: Define o número de árvores no modelo, afetando a complexidade e o tempo de treinamento.\n",
    "\n",
    "- learning_rate: Controla a contribuição de cada árvore para o modelo, influenciando a taxa de aprendizado e a robustez.\n",
    "\n",
    "- max_depth: Limita a profundidade das árvores, ajudando a evitar overfitting.\n",
    "\n",
    "- min_samples_split: Define o número mínimo de amostras para dividir um nó, regulando a complexidade das divisões das árvores.\n",
    "\n",
    "- min_samples_leaf: Especifica o número mínimo de amostras em uma folha, controlando a complexidade das folhas da árvore e ajudando a evitar overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do GridSearch:\n",
      "+-----------------------------------------+----------------------------+\n",
      "|           Melhores Parâmetros           | Pontuação do Melhor Modelo |\n",
      "+-----------------------------------------+----------------------------+\n",
      "| {'lr__C': 1.0, 'rf__n_estimators': 200} |            0.96            |\n",
      "+-----------------------------------------+----------------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Carregando o conjunto de dados iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Definindo os classificadores\n",
    "clf1 = LogisticRegression(random_state=1, max_iter=1000)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "# Definindo o classificador de votação\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Definindo os parâmetros a serem testados\n",
    "params = {'lr__C': [1.0, 100.0], 'rf__n_estimators': [20, 200]}\n",
    "\n",
    "# Executando o GridSearchCV\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(iris.data, iris.target)\n",
    "\n",
    "# Obtendo os resultados do GridSearch\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_\n",
    "\n",
    "# Criando uma tabela com os resultados\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Melhores Parâmetros\", \"Pontuação do Melhor Modelo\"]\n",
    "table.add_row([best_params, best_score])\n",
    "\n",
    "# Imprimindo a tabela\n",
    "print(\"Resultados do GridSearch:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Correção da maior diferença entre GBM e Stochastic GBM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior diferença entre o GBM e o SGBM é que o SGBM usa mais sorteio do que o GBM na hora de criar as árvores de decisão e escolher os dados de treinamento. Isso faz com que o SGBM seja mais variado e menos viciado do que o GBM, o que pode ser bom ou ruim dependendo da situação. Os dois algoritmos são formas de melhorar o Gradient Boosting, que é um método que combina várias árvores de decisão para criar um modelo mais forte.\n",
    "\n",
    "Chamamos de amostragem aleatória quando você usa apenas uma parte dos dados de treinamento para cada modelo, em vez de usar todos. Isso ajuda a evitar que o modelo se adapte demais aos dados de treinamento e perca a capacidade de generalizar para novos dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
